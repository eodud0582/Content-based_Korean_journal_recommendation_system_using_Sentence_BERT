{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "032889c6-dd6c-421a-924b-6f2ac33548a8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Sentence BERT를 이용한 내용 기반 국문 저널 추천 시스템</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66e327-d887-4dca-8b19-65e7ff34a0dd",
   "metadata": {},
   "source": [
    "# III. Gompertz Function 적용 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15b22e-0982-41c7-a3e2-edaee46ea8d1",
   "metadata": {},
   "source": [
    "---\n",
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4b439260-381d-4c5d-a0ab-94339ab99b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "import sys\n",
    "sys.path.append('..') # parent directory 경로 추가\n",
    "\n",
    "from common import *\n",
    "from my import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# random seed 고정 \n",
    "import os, random\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "#     tf.random.set_seed(seed) # Tensorflow 사용시 \n",
    "SEED = 777\n",
    "set_seeds(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c139c5e1-a2db-4730-bcd6-d66e3d1d893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt, Mecab\n",
    "\n",
    "import math\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74a251-a601-437d-a5c2-4a55b3e1bab4",
   "metadata": {},
   "source": [
    "---\n",
    "# Train 데이터 관련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ac90ff5d-4ecd-4c4e-b1bf-80b202486e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92760, 7)\n",
      "(92760,)\n",
      "92760\n",
      "(92760, 768)\n"
     ]
    }
   ],
   "source": [
    "# 전처리한 train 데이터(dataframe) 다시 읽어오기\n",
    "train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "print(train.shape)\n",
    "\n",
    "# Train y \n",
    "train_y = train['journal'] # Train 데이터 document id - journal\n",
    "print(train_y.shape)\n",
    "\n",
    "# Train 데이터셋 기준 각 document id - index 매핑 (데이터셋에서의 위치)\n",
    "train_id_index = pd.Series(range(len(train.index)), index=train.index)\n",
    "print(len(train_id_index))\n",
    "\n",
    "# Train SBERT embedding npy 파일 다시 읽기\n",
    "train_embed = np.load('./data/train_embed.npy')\n",
    "print(train_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20334954-f811-41d0-976b-ff63d158760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal\n",
      "CRM연구                                                      0\n",
      "Child Health Nursing Research                              1\n",
      "Clinical and Experimental Reproductive Medicine            2\n",
      "Clinics in Shoulder and Elbow                              3\n",
      "Communications for Statistical Applications and Methods    4\n",
      "dtype: int64\n",
      "journal\n",
      "해양환경안전학회지    263\n",
      "혜화의학회지       264\n",
      "화약ㆍ발파        265\n",
      "환경영향평가       266\n",
      "환경정책연구       267\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 저널명 - Index 매핑  (저널 고정 순서)\n",
    "journ_order = train.groupby('journal').groups.keys()\n",
    "journ_index = pd.Series(range(len(journ_order)), index=journ_order)\n",
    "print(journ_index[:5])\n",
    "print(journ_index[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "056d7f7d-1631-4a9f-94da-524710f2871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 43041)\n",
      "(268, 135402)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Journal-Title Matrix (JTM)\n",
    "# journal별 title CountVectorize\n",
    "train_journ_tt = train.groupby('journal')['title_nn'].apply(' '.join) # journal별로 모든 논문들 title text 합치기\n",
    "count_vect_tt = CountVectorizer(min_df=1, ngram_range=(1,1)) # unigram\n",
    "jtm = count_vect_tt.fit_transform(train_journ_tt) # sparse matrix\n",
    "print(jtm.shape)\n",
    "\n",
    "# csr matrix -> dataframe\n",
    "# jtm_df = pd.DataFrame(jtm.toarray(), index=train_journ_tt.index, columns=count_vect_tt.get_feature_names_out())\n",
    "\n",
    "# ================================================= #\n",
    "# Journal-Keyword Matrix (JKM)\n",
    "# journal별 keyword CountVectorize\n",
    "train_journ_kw = train.groupby('journal')['keyword'].apply(' '.join) # journal별로 모든 논문들 keyword text 합치기\n",
    "count_vect_kw = CountVectorizer(min_df=1, ngram_range=(1,1)) # unigram\n",
    "jkm = count_vect_kw.fit_transform(train_journ_kw) # sparse matrix\n",
    "print(jkm.shape)\n",
    "\n",
    "# csr matrix -> dataframe\n",
    "# jkm_df = pd.DataFrame(jkm.toarray(), index=train_journ_kw.index, columns=count_vect_kw.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d0517-708f-479e-af5a-5ed2b0c002eb",
   "metadata": {},
   "source": [
    "---\n",
    "# Test 데이터 관련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9c131e0b-f1c5-4ac6-9146-7b0452b87994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10307, 7)\n",
      "(10307,)\n",
      "10307\n",
      "(10307, 768)\n"
     ]
    }
   ],
   "source": [
    "# 전처리한 test 데이터(dataframe) 다시 읽어오기\n",
    "test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "print(test.shape)\n",
    "\n",
    "# Test y\n",
    "test_y = test['journal'] # Test 데이터 document id - journal\n",
    "print(test_y.shape)\n",
    "\n",
    "# Test 데이터셋 기준 document id - index 매핑 (데이터셋에서의 위치)\n",
    "test_id_index = pd.Series(range(len(test.index)), index=test.index)\n",
    "print(len(test_id_index))\n",
    "\n",
    "# Test SBERT embedding npy 파일 다시 읽기\n",
    "test_embed = np.load('./data/test_embed.npy')\n",
    "print(test_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a497ab-3619-4167-a73a-9564880f3ea6",
   "metadata": {},
   "source": [
    "## 문서 vs. 문서 유사도 (S1)\n",
    "- Test 데이터 사용\n",
    "- Test 데이터의 SBERT 임베딩된 Abstract vs. Train 데이터의 SBERT 임베딩된 Abstract -> 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "af069bf3-a434-4566-b29c-b19ca2d909c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10307, 92760)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5445481 , 0.33625972, 0.1614262 , ..., 0.3330929 , 0.557525  ,\n",
       "        0.31247985],\n",
       "       [0.6503759 , 0.45653108, 0.29908445, ..., 0.50919765, 0.6316433 ,\n",
       "        0.48862016],\n",
       "       [0.31182605, 0.34367323, 0.24949932, ..., 0.44575486, 0.24206194,\n",
       "        0.45320866],\n",
       "       [0.42790985, 0.48927057, 0.2149891 , ..., 0.47800317, 0.53168607,\n",
       "        0.46760318],\n",
       "       [0.46252072, 0.38382778, 0.40913084, ..., 0.26628563, 0.23586869,\n",
       "        0.44414553]], dtype=float32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test document의 embedding vectors & train document의 embedding vectors 코사인 유사도 분석\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "s1 = cosine_similarity(test_embed, train_embed) # test embed vs. train embed\n",
    "print(s1.shape)\n",
    "s1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7652a73f-b892-4f73-8cfc-dff73e482269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 배열 파일로 저장\n",
    "# np.save('s1', s1)\n",
    "\n",
    "# 저장한 npy 파일 다시 읽기\n",
    "# s1 = np.load('s1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68506419-575f-4eea-8f30-bdac4d215c08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Customized Function | List of Journals (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c782ac-c37a-4a20-b95d-cc54d975daad",
   "metadata": {},
   "source": [
    "- 곰페르츠 함수(Gompertz function) 적용\n",
    "    - S-curved 형태가 됨\n",
    "- 저널별 최종 점수 계산 방법:\n",
    "    - 저널별로 위 유사도 점수를 평균(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75635f7f-126e-4433-b26c-f0ce4d612793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 10307/10307 [07:31<00:00, 22.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10307\n",
      "['한국가금학회지', '대한한방부인과학회지', 'Journal of Animal Science and Technology', '원예과학기술지', '농약과학회지', 'Weed & Turfgrass Science', '농업과학연구', '시설원예ㆍ식물공장', 'Clinical and Experimental Reproductive Medicine', 'Radiation Oncology Journal']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import collections\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "def get_all_sim_journ(doc_sims, threshold=0.7):\n",
    "    '''\n",
    "    doc_sims : numpy array; 각 문서vs.문서 유사도 점수\n",
    "    threshold : \"높은 유사도\"의 기준\n",
    "    '''\n",
    "    # Gompertz function을 사용하여 similarity score 계산\n",
    "    a = 0\n",
    "    b = -0.1\n",
    "    c = 100\n",
    "    d = 60\n",
    "    sim_weighted = a + (c-a) * (1-math.exp(1)**(-math.exp(1)**(-b*(doc_sims*100-d)))) # 문서별 문서vs.문서 유사도\n",
    "    \n",
    "    # 각 점수마다 해당 document id 붙이기 ([document id, weighted 유사도 점수] 형태로)\n",
    "    sim_weighted = list(zip(train_id_index.index, sim_weighted)) # e.g. ('JAKO201610364779000', 0.5445481)\n",
    "    \n",
    "    # weighted 유사도 >= threshold\n",
    "    #sim_weighted = list(filter(lambda x: x[1] >= threshold, sim_weighted))\n",
    "    \n",
    "    # [document id, 유사도 점수] -> 저널별 [journal 이름, 유사도 총 점수]\n",
    "    sum_dict = collections.defaultdict(list)\n",
    "    for doc_id, sim_score in sim_weighted:\n",
    "        journ_name = train_y[doc_id] # 저널명 가져오기\n",
    "        sum_dict[journ_name].append(sim_score) # 저널별 유사도 점수 합치기\n",
    "    \n",
    "    mean_dict = {key: np.mean(values) for key, values in sum_dict.items()}\n",
    "    \n",
    "    # 총 유사도 점수가 높은 순서대로 저널 이름 정렬 (S-Sort)\n",
    "    journ_sorted = list(dict(sorted(mean_dict.items(), key=itemgetter(1), reverse=True)).keys())\n",
    "    \n",
    "    return journ_sorted\n",
    "\n",
    "# 추천 후보 저널 - list of journals (R)\n",
    "workers = os.cpu_count() * 2\n",
    "with parallel_backend(backend='loky', n_jobs=workers):\n",
    "    r = list(Parallel()(delayed(get_all_sim_journ)(doc_sims) for doc_sims in tqdm(s1, position=0, leave=True)))\n",
    "\n",
    "print(len(r))\n",
    "print(r[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc401f2-6ad0-4810-b71e-26709ba92302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 유사도 높은 journal 리스트 pickle로 저장\n",
    "# with open('./data/r_gompertz.pkl', 'wb') as f:\n",
    "#     pickle.dump(r, f)\n",
    "\n",
    "# 저장한 pickle 다시 읽기\n",
    "# with open('./data/r_gompertz.pkl', 'rb') as f:\n",
    "#     r = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6e125-bd91-4ddc-9a6e-3a6804c87d79",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "# # Phase 2: 후보 저널 재정렬\n",
    "- 후보 저널 재정렬\n",
    "    - 입력 문서 vs. 저널의 Title, Keyword 유사도 기반 (S2+S3)\n",
    "    - 초록 외 키워느나 제목이 입력된 경우, 저널에 출판된 문서들(train)의 키워드와 일치도를 계산하여 추천 결과를 개선하기 위한 과정\n",
    "    - 후보 저널 리스트업 된 것에 순위 sort하기 위한 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66be32f9-9041-4608-8793-fbd8a9216668",
   "metadata": {},
   "source": [
    "## 문서 vs. 저널 유사도 (S2+S3)\n",
    "- Keyword 유사도 (S2) + Title 유사도 (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de8c5a-a932-412d-bb59-2bbed06dc2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10307,)\n",
      "(10307, 135402)\n",
      "(10307, 268)\n",
      "(10307,)\n",
      "(10307, 43041)\n",
      "(10307, 268)\n",
      "(10307, 268)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.16510017, 0.09318388, 0.07643517, ..., 0.03647989, 0.12525107,\n",
       "        0.07358115],\n",
       "       [0.        , 0.        , 0.        , ..., 0.0032244 , 0.00759136,\n",
       "        0.00520297],\n",
       "       [0.1249516 , 0.06112054, 0.05013484, ..., 0.19781094, 0.13443356,\n",
       "        0.11188206],\n",
       "       [0.        , 0.        , 0.        , ..., 0.03224398, 0.01180878,\n",
       "        0.00346865],\n",
       "       [0.11973687, 0.12910096, 0.07206377, ..., 0.17196787, 0.17375783,\n",
       "        0.1314451 ]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ================================================= #\n",
    "# test document vs. train journal의 keyword 유사도 구하기 (S2)\n",
    "\n",
    "# 각 Test 데이터의 문서별 Keyword Matrix 생성 (Test JKM)\n",
    "test_doc_kw = test['keyword']\n",
    "print(test_doc_kw.shape)\n",
    "\n",
    "# document-keyword matrix 생성 (JKM 생성때 fit된 count vectorizer 사용)\n",
    "test_doc_kw_mat = count_vect_kw.transform(test_doc_kw)\n",
    "print(test_doc_kw_mat.shape)\n",
    "\n",
    "# dataframe 형태로 확인\n",
    "# d_kw_df = pd.DataFrame(d_kw_mat.toarray(), index=d_kw.index, columns=count_vect_kw.get_feature_names_out())\n",
    "\n",
    "# keyword 사이의 document vs. journal 유사도 계산\n",
    "s2 = cosine_similarity(test_doc_kw_mat, jkm)\n",
    "print(s2.shape)\n",
    "\n",
    "# ================================================= #\n",
    "# test document vs. train journal의 title 유사도 구하기 (S3)\n",
    "\n",
    "# 각 Test 데이터의 문서별 Title Matrix 생성 (Test JTM)\n",
    "test_doc_tt = test['title_nn']\n",
    "print(test_doc_tt.shape)\n",
    "\n",
    "# document-title matrix 생성 (JTM 생성때 fit된 count vectorizer 사용)\n",
    "test_doc_tt_mat = count_vect_tt.transform(test_doc_tt)\n",
    "print(test_doc_tt_mat.shape)\n",
    "\n",
    "# dataframe 형태로 확인\n",
    "# d_tt_df = pd.DataFrame(d_tt_mat.toarray(), index=d_tt.index, columns=count_vect_tt.get_feature_names_out())\n",
    "\n",
    "# title 사이의 document vs. journal 유사도 계산\n",
    "s3 = cosine_similarity(test_doc_tt_mat, jtm)\n",
    "print(s3.shape)\n",
    "\n",
    "# ================================================= #\n",
    "# Title 코사인 유사도 + Keyword 코사인 유사도 더하기 (S2+S3)\n",
    "s23 = s2 + s3\n",
    "print(s23.shape)\n",
    "s23[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd873aac-3590-4295-aba3-00af16549599",
   "metadata": {},
   "source": [
    "## 추천 저널 리스트 재배치\n",
    "\n",
    "**Note: 코드가 실행되는 곳은 아래 \"Phase\"의 모델링 부분에서 실행 됨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6fb59-28d8-43cf-91c8-d91aac610a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 vs. 저널 유사도(S2+S3)에 따른 후보 저널 재배치\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# def resort_r(tt_kw_s, i):\n",
    "#     # doc-journal별 유사도 점수에 journal 이름 붙이기 \n",
    "#     journ_scores = list(zip(journ_index.index, tt_kw_s[i])) # journal 이름 붙이기\n",
    "#     # 높은 유사도순으로 journal 정렬\n",
    "#     journ_scores_sorted = sorted(journ_scores, key=lambda x: x[1], reverse=True) \n",
    "#     # journal이 기존 list of journals에 있는 journal이라면 포함 (정렬된 순서에 맞춰 새로운 R 생성)\n",
    "#     journ_filtered = [journ for journ, sim in journ_scores_sorted if journ in top_k_journs[i]]\n",
    "#     return journ_filtered\n",
    "\n",
    "def resort_r(tt_kw_s, top_k_journs, i):\n",
    "    # 각 doc의 journal별 title+keyword 유사도 점수에 journal 이름 붙이기 \n",
    "    journ_scores = dict(zip(journ_index.index, tt_kw_s[i])) # journal 이름 붙이기\n",
    "    # 높은 유사도순으로 journal 재배치 (기존 list of journals에 있는 저널만 포함) -> 새로운 R 생성\n",
    "    journ_sorted = list(dict(sorted(filter(lambda x: x[0] in top_k_journs[i], journ_scores.items()), key=itemgetter(1), reverse=True)).keys())\n",
    "    return journ_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce5214-3b0f-449c-af18-054a2f55e7c2",
   "metadata": {},
   "source": [
    "---\n",
    "# # Phase 3: 후보 저널 추가\n",
    "- Test 데이터셋 사용\n",
    "- 후보 저널 추가\n",
    "    - 저널 vs. 저널 유사도 (S4) 기반\n",
    "    - Title, Keyword 유사도\n",
    "    - 새로 추가할 수 있는, 상위 후보 저널과 유사한 후보 저널을 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c68c3-d33c-47be-9a64-8b0bedcc55ad",
   "metadata": {},
   "source": [
    "## 저널 vs. 저널 유사도 (S4) | 후보 저널 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "129104b2-06d9-471f-a39a-97d8403dada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "# 저널 vs. 저널 유사도 (S4) 계산 및 후보 저널 추가\n",
    "def find_other_sim_journ(cur_top_journs):\n",
    "    '''\n",
    "    # Description :\n",
    "    # 추천 저널 후보 리스트에서, 맨 앞의 최상위 저널(R1) 1개에 대해 저널들과의 유사도를 분석 (저널 vs. 저널 유사도 분석)\n",
    "    # 이후, 유사도 높은 저널부터 순차적으로 추천 저널 후보 리스트에 없는 저널을 찾기\n",
    "    # 만약 찾았지만, 발견한 저널의 유사도 점수가 0보다 크지 않다면 (그 뒤 후보들의 유사도는 볼 필요 없이)\n",
    "    # R1은 pass하고 다음 상위 저널(R2, R3, ... 순차적으로)로 같은 방법으로 탐색\n",
    "    '''\n",
    "    def if_not_in_r(x):\n",
    "        # list of journals에 이미 있는지/없는지 확인\n",
    "        if x[0] in cur_top_journs:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    # list of journals이 애초에 비어있는 경우\n",
    "    if not len(cur_top_journs):\n",
    "        # 빈 list of journals 그대로 반환\n",
    "        return cur_top_journs\n",
    "    \n",
    "    # 추가 후보 저널 탐색\n",
    "    add_journ_found = False\n",
    "    for i in range(len(cur_top_journs)):\n",
    "        # 현재 선택된 상위 저널\n",
    "        best_journ = cur_top_journs[i] # 맨 앞의(최상위) 후보 저널부터 하나씩\n",
    "\n",
    "        # # 해당 상위 저널과 다른 저널들의 title 유사도 구하기\n",
    "        # best_j_tt = train[train['journal'] == best_journ].groupby('journal')['title_nn'].apply(' '.join) # 해당 상위 저널의 (모든 doc의) 전처리된 title text 모으기\n",
    "        # best_j_tt_mat = count_vect_tt.transform(best_j_tt) # 상위 저널의 journal-title matrix 생성 (train JTM 생성시 fit한 count vectorizer로 transform)\n",
    "        best_j_tt_mat = jtm[journ_index[best_journ]]\n",
    "        best_tt_sim = cosine_similarity(best_j_tt_mat, jtm) # 상위 저널 JTM - train JTM 과의 title 코사인 유사도 (1, 268)\n",
    "\n",
    "        # 해당 상위 저널과 다른 후보 저널들의 keyword 유사도 구하기\n",
    "        # best_j_kw = train[train['journal'] == best_journ].groupby('journal')['keyword'].apply(' '.join) # 해당 상위 저널의 (모든 doc의) 전처리된 keyword text 모으기\n",
    "        # best_j_kw_mat = count_vect_kw.transform(best_j_kw) # 상위 저널의 journal-keyword matrix 생성 (train JKM 생성시 fit한 count vectorizer로 transform)\n",
    "        best_j_kw_mat = jkm[journ_index[best_journ]]\n",
    "        best_kw_sim = cosine_similarity(best_j_kw_mat, jkm) # 상위 저널 JKM - train JKM 과의 keyword 코사인 유사도\n",
    "\n",
    "        # 해당 후보 저널의 다른 저널들과의 최종 유사도 구하기\n",
    "        s4 = best_tt_sim + best_kw_sim # Title 코사인 유사도 + Keyword 코사인 유사도 더하기\n",
    "        s4 = s4[0] # 268개 각 저널별 유사도 점수; test document 1개씩 처리 중이기 때문에 [i]가 아닌 [0] indexing\n",
    "        \n",
    "        # 높은 유사도 순으로 후보 저널 정렬0\n",
    "        best_jj_sim = sorted(dict(zip(journ_index.index, s4)).items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "        # 그 중 기존 list of journals에 없는 저널 탐색 (유사도 높은 후보부터)\n",
    "        new_journ_found = next(filter(if_not_in_r, best_jj_sim), None)\n",
    "        if new_journ_found != None: # list of journals에 없는 후보 저널 1개를 찾았고,\n",
    "            if new_journ_found[1] > 0: # 해당 저널의 유사도 점수가 0보다 크다면\n",
    "                # 후보 저널 추가\n",
    "                top_journs_added = cur_top_journs + [new_journ_found[0]] # list of journals에 추가\n",
    "                add_journ_found = True\n",
    "                return top_journs_added\n",
    "            else: # 유사도 점수가 0이면, 다음 후보 저널로 탐색 (R2,R3,...)\n",
    "                continue\n",
    "        else: # list of journals에 없는 후보 저널이 없다면(모든 후보 저널이 이미 다 list of journals에 있다면)\n",
    "            continue # 다음 후보 저널로 탐색 (R2,R3,...)\n",
    "    \n",
    "    # 모든 후보 저널을(R1,R2,R3,...) 다 탐색했지만, 적합한 후보 저널을 못 찾았다면\n",
    "    if not add_journ_found:\n",
    "        top_journs_added = cur_top_journs # 기존 list of journals 그대로 사용\n",
    "        return top_journs_added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc52eea0-7c22-4618-b2f6-1bfa2b19fa55",
   "metadata": {},
   "source": [
    "# # 모델링 및 평가\n",
    "- Best model 사용\n",
    "- Top-K 저널 추천 및 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4653e0-bb50-4b90-af35-03a07240749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 모델 평가 지표 함수\n",
    "\n",
    "# Micro Accuracy\n",
    "def get_acc_micro(y_pred, y_true):\n",
    "    return np.mean(np.array([1 if y_true[i] in y_pred[i] else 0 for i in range(len(y_true))])) \n",
    "\n",
    "# Macro Accuracy\n",
    "def get_acc_macro(y_pred, y_true):\n",
    "    global each_journ_ox, each_journ_mean_acc\n",
    "    # 저널별로 맞은 것은 1, 틀린 것은 0으로 넣기\n",
    "    each_journ_ox = collections.defaultdict(list)\n",
    "    for journ_actual, journs_rec in list(zip(y_true, y_pred)):\n",
    "        if journ_actual in journs_rec:\n",
    "            each_journ_ox[journ_actual].append(1)\n",
    "        else:\n",
    "            each_journ_ox[journ_actual].append(0)\n",
    "    # 저널별 평균 accuracy 계산\n",
    "    each_journ_mean_acc = {key: np.mean(values) for key, values in each_journ_ox.items()} # dictionary comprehension\n",
    "    # 저널별 평균 accuracy의 전체 평균 계산\n",
    "    mean_of_mean_acc = np.mean(list(each_journ_mean_acc.values()))\n",
    "    return mean_of_mean_acc\n",
    "\n",
    "# MRR\n",
    "def get_mrr(y_pred, y_true):\n",
    "    # 각 예측별 reciprocal rank 구하기 (실제 저널이 추천 리스트에서 몇 번째에 위치하는지)\n",
    "    recip_rank_computed = []\n",
    "    for journ_actual, journs_rec in list(zip(y_true, y_pred)):\n",
    "        try:\n",
    "            # 추천 리스트에 있다면, 위치 번호에 역수 취하기 (앞에 나올수록 좋은 모델이니까)\n",
    "            recip_rank = 1 / (journs_rec.index(journ_actual) + 1) # 1/(index + 1)\n",
    "        except:\n",
    "            # 추천 리스트에 없다면 0\n",
    "            recip_rank = 0\n",
    "        recip_rank_computed.append(recip_rank)\n",
    "    # Mean Reciprocal Rank 계산\n",
    "    mmr = np.mean(recip_rank_computed)\n",
    "    return mmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9b42bd22-7843-4522-a4ea-d829abca7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 저널 수(K) 설정\n",
    "# Top-3, Top-5, Top-10, Top-15, Top-20\n",
    "\n",
    "K_list = [3, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c49cd-92ab-4d90-8c4b-519aa9916fe3",
   "metadata": {},
   "source": [
    "## Phase 1+2+3: Abs + Tt + Kw\n",
    "- Top-(K-1) 저널 추출 후, 유사 저널 1개 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf354ff4-f65e-480c-ae6b-fa2973809bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2439.25it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:42<00:00, 240.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2503.21it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:38<00:00, 269.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2507.49it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:39<00:00, 263.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2483.55it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:39<00:00, 260.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2495.11it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:39<00:00, 260.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>0.6724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.7806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.2486</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>0.3767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.3297 0.4265  0.5540  0.6189  0.6724\n",
       "macro_acc 0.4199 0.5353  0.6691  0.7396  0.7806\n",
       "mrr       0.2486 0.2973  0.3450  0.3644  0.3767"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 모델에서 sum이 아닌 mean 사용한 모델 평가\n",
    "# 1) 모든 유사도에 대한 mean (O)\n",
    "\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s23\n",
    "\n",
    "accuracy_results = pd.DataFrame() # 정확도 결과 df\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K-1\n",
    "    first_n = K-1\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    workers = -1\n",
    "    with parallel_backend(backend='threading', n_jobs=workers):\n",
    "        top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_s_curve = accuracy_results.copy()\n",
    "print(acc_s_curve)\n",
    "acc_s_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2f5c620-f6e2-4917-9057-57c9eaab7261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.3297 0.4265  0.5540  0.6189  0.6724\n",
      "macro_acc 0.4199 0.5353  0.6691  0.7396  0.7806\n",
      "mrr       0.2486 0.2973  0.3450  0.3644  0.3767\n"
     ]
    }
   ],
   "source": [
    "print(acc_s_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e22079c3-d3a0-4592-8589-0bcd995d35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_s_curve.to_csv('./acc_scurve_model/acc_s_curve.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_s_curve = pd.read_csv('./acc_scurve_model/acc_s_curve.csv', index_col=0)\n",
    "# acc_s_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f0fbe-4982-4064-99b7-eba31969ac3d",
   "metadata": {},
   "source": [
    "# 끝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
