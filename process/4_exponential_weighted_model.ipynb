{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de404334-688c-48ff-880c-e557bee54129",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Sentence BERT를 이용한 내용 기반 국문 저널 추천 시스템</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0c2ab-2e7e-4a64-8391-64a83d017413",
   "metadata": {},
   "source": [
    "# IV. Exponential Function + Weight 적용 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe997c-55c2-4142-8a56-5c53f41dc8eb",
   "metadata": {},
   "source": [
    "---\n",
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4b439260-381d-4c5d-a0ab-94339ab99b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "import sys\n",
    "sys.path.append('..') # parent directory 경로 추가\n",
    "\n",
    "from common import *\n",
    "from my import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# random seed 고정 \n",
    "import os, random\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "#     tf.random.set_seed(seed) # Tensorflow 사용시 \n",
    "SEED = 777\n",
    "set_seeds(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c139c5e1-a2db-4730-bcd6-d66e3d1d893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt, Mecab\n",
    "\n",
    "import math\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191a231-a67f-4dc2-81c0-d78d0df6ed74",
   "metadata": {},
   "source": [
    "---\n",
    "# Train 데이터 관련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ac90ff5d-4ecd-4c4e-b1bf-80b202486e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92760, 7)\n",
      "(92760,)\n",
      "92760\n",
      "(92760, 768)\n"
     ]
    }
   ],
   "source": [
    "# 전처리한 train 데이터(dataframe) 다시 읽어오기\n",
    "train = pd.read_csv('./data/train.csv', index_col=0)\n",
    "print(train.shape)\n",
    "\n",
    "# Train y \n",
    "train_y = train['journal'] # Train 데이터 document id - journal\n",
    "print(train_y.shape)\n",
    "\n",
    "# Train 데이터셋 기준 각 document id - index 매핑 (데이터셋에서의 위치)\n",
    "train_id_index = pd.Series(range(len(train.index)), index=train.index)\n",
    "print(len(train_id_index))\n",
    "\n",
    "# Train SBERT embedding npy 파일 다시 읽기\n",
    "train_embed = np.load('./data/train_embed.npy')\n",
    "print(train_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20334954-f811-41d0-976b-ff63d158760b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal\n",
      "CRM연구                                                      0\n",
      "Child Health Nursing Research                              1\n",
      "Clinical and Experimental Reproductive Medicine            2\n",
      "Clinics in Shoulder and Elbow                              3\n",
      "Communications for Statistical Applications and Methods    4\n",
      "dtype: int64\n",
      "journal\n",
      "해양환경안전학회지    263\n",
      "혜화의학회지       264\n",
      "화약ㆍ발파        265\n",
      "환경영향평가       266\n",
      "환경정책연구       267\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 저널명 - Index 매핑  (저널 고정 순서)\n",
    "journ_order = train.groupby('journal').groups.keys()\n",
    "journ_index = pd.Series(range(len(journ_order)), index=journ_order)\n",
    "print(journ_index[:5])\n",
    "print(journ_index[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "056d7f7d-1631-4a9f-94da-524710f2871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268, 43041)\n",
      "(268, 135402)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Journal-Title Matrix (JTM)\n",
    "# journal별 title CountVectorize\n",
    "train_journ_tt = train.groupby('journal')['title_nn'].apply(' '.join) # journal별로 모든 논문들 title text 합치기\n",
    "count_vect_tt = CountVectorizer(min_df=1, ngram_range=(1,1)) # unigram\n",
    "jtm = count_vect_tt.fit_transform(train_journ_tt) # sparse matrix\n",
    "print(jtm.shape)\n",
    "\n",
    "# csr matrix -> dataframe\n",
    "# jtm_df = pd.DataFrame(jtm.toarray(), index=train_journ_tt.index, columns=count_vect_tt.get_feature_names_out())\n",
    "\n",
    "# ================================================= #\n",
    "# Journal-Keyword Matrix (JKM)\n",
    "# journal별 keyword CountVectorize\n",
    "train_journ_kw = train.groupby('journal')['keyword'].apply(' '.join) # journal별로 모든 논문들 keyword text 합치기\n",
    "count_vect_kw = CountVectorizer(min_df=1, ngram_range=(1,1)) # unigram\n",
    "jkm = count_vect_kw.fit_transform(train_journ_kw) # sparse matrix\n",
    "print(jkm.shape)\n",
    "\n",
    "# csr matrix -> dataframe\n",
    "# jkm_df = pd.DataFrame(jkm.toarray(), index=train_journ_kw.index, columns=count_vect_kw.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e23b2-e853-463e-94f6-ffce0313d515",
   "metadata": {},
   "source": [
    "---\n",
    "# Test 데이터 관련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9c131e0b-f1c5-4ac6-9146-7b0452b87994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10307, 7)\n",
      "(10307,)\n",
      "10307\n",
      "(10307, 768)\n"
     ]
    }
   ],
   "source": [
    "# 전처리한 test 데이터(dataframe) 다시 읽어오기\n",
    "test = pd.read_csv('./data/test.csv', index_col=0)\n",
    "print(test.shape)\n",
    "\n",
    "# Test y\n",
    "test_y = test['journal'] # Test 데이터 document id - journal\n",
    "print(test_y.shape)\n",
    "\n",
    "# Test 데이터셋 기준 document id - index 매핑 (데이터셋에서의 위치)\n",
    "test_id_index = pd.Series(range(len(test.index)), index=test.index)\n",
    "print(len(test_id_index))\n",
    "\n",
    "# Test SBERT embedding npy 파일 다시 읽기\n",
    "test_embed = np.load('./data/test_embed.npy')\n",
    "print(test_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aae772-6b17-4f45-8eb1-7ef07caa2cd2",
   "metadata": {},
   "source": [
    "---\n",
    "# # Phase 1: 후보 저널 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df73021-4092-4c79-bbfd-0de2f3cc88a0",
   "metadata": {},
   "source": [
    "## 문서 vs. 문서 유사도 (S1)\n",
    "- Test 데이터 사용\n",
    "- Test 데이터의 SBERT 임베딩된 Abstract vs. Train 데이터의 SBERT 임베딩된 Abstract -> 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115ca93-14a1-4ad2-bc0f-84308ec511d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10307, 92760)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5445481 , 0.33625972, 0.1614262 , ..., 0.3330929 , 0.557525  ,\n",
       "        0.31247985],\n",
       "       [0.6503759 , 0.45653108, 0.29908445, ..., 0.50919765, 0.6316433 ,\n",
       "        0.48862016],\n",
       "       [0.31182605, 0.34367323, 0.24949932, ..., 0.44575486, 0.24206194,\n",
       "        0.45320866],\n",
       "       [0.42790985, 0.48927057, 0.2149891 , ..., 0.47800317, 0.53168607,\n",
       "        0.46760318],\n",
       "       [0.46252072, 0.38382778, 0.40913084, ..., 0.26628563, 0.23586869,\n",
       "        0.44414553]], dtype=float32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test document의 embedding vectors & train document의 embedding vectors 코사인 유사도 분석\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "s1 = cosine_similarity(test_embed, train_embed) # test embed vs. train embed\n",
    "print(s1.shape)\n",
    "s1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513abbd-65d4-4ff8-bd68-5eeda78a57c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Customized Function | List of Journals (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaed58f-def1-4071-a46d-51a46882cfea",
   "metadata": {},
   "source": [
    "- Exponential Function 적용 및 추가 가중치 부여\n",
    "- 문서별 유사도 점수 계산 방법:\n",
    "    - 코사인 유사도 0.7 = 70, 1.0 = 1000이 되도록 exponential function 적용\n",
    "    - 저널별로 유사도 높은(>threshold) document 수를 세고, 각 해당 저널에 속하는 document별 exponential function 적용된 유사도에 \"document 수\"를 추가 가중치(weight)로 부여\n",
    "        - 유사도 높은 document가 많은 저널일수록 더 중요 할 수 있으니, 저널의 유사도를 최종 유사도에 추가로 반영한 것\n",
    "- 저널별 최종 점수 계산 방법:\n",
    "    - 저널별로 위 유사도 점수를 평균(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8589c391-47c0-4717-9395-475ed3b6526f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                | 55/10307 [1:47:52<335:07:07, 117.68s/it]\n",
      "  0%|                                | 15/10307 [1:45:14<1203:28:43, 420.96s/it]\n",
      "100%|█████████████████████████████████████| 10307/10307 [08:38<00:00, 19.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10307\n",
      "['원예과학기술지', '시설원예ㆍ식물공장', '한국가금학회지', '한국응용곤충학회지', '농약과학회지', '한국환경생태학회지', 'Weed & Turfgrass Science', 'Journal of Animal Science and Technology', 'Restorative Dentistry and Endodontics', '대한환경공학회지']\n"
     ]
    }
   ],
   "source": [
    "# 1. 각 train document가 속한 저널이 유사도 0.7 이상의 document가 몇 개인지 따라 weight 부여 (-> 기존 exponential function에 더하기)\n",
    "# -> 다시 말해, 각 train document의 유사도 점수 뿐만 아니라, 현재 test document와 관련이 클것 같은 저널일수록, 저널의 document일수록, 그 만큼의 가중치가 더해짐\n",
    "# 2. 그리고, 저널별 모든 해당되는 document의 weighted 유사도를 sum하는 것이 아닌 mean하여 최종 score 게산\n",
    "\n",
    "import math\n",
    "import collections\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "def get_all_sim_journ(doc_sims, threshold=0.7):\n",
    "    '''\n",
    "    doc_sims : numpy array; 각 문서vs.문서 유사도 점수\n",
    "    threshold : \"높은 유사도\"의 기준\n",
    "    '''\n",
    "    # weighted similarity score 계산\n",
    "    doc_and_scores = dict(zip(train_id_index.index, doc_sims))\n",
    "    journ_and_scores = list(zip(train_y.values, doc_sims))\n",
    "    docs_over_th = list((dict(filter(lambda x: x[1] >= threshold, doc_and_scores.items())).keys()))\n",
    "    journs_over_th = collections.Counter(train_y[docs_over_th].values)\n",
    "    weight = [journs_over_th[journ_name] if journ_name in journs_over_th else 0 for journ_name in train_y.values]\n",
    "    \n",
    "    sim_weighted = ((0.135 * np.exp(0.0891 * (doc_sims*100))) + 0.5) + weight # document별 weighted similarity\n",
    "    \n",
    "    # 각 점수마다 해당 document id 붙이기 ([document id, weighted 유사도 점수] 형태로)\n",
    "    sim_weighted = list(zip(train_id_index.index, sim_weighted)) # e.g. ('JAKO201610364779000', 0.5445481)\n",
    "    \n",
    "    # weighted 유사도 >= threshold\n",
    "    #sim_weighted = list(filter(lambda x: x[1] >= threshold, sim_weighted))\n",
    "    \n",
    "    # [document id, 유사도 점수] -> 저널별 [journal 이름, 유사도 총 점수]\n",
    "    sum_dict = collections.defaultdict(list)\n",
    "    for doc_id, sim_score in sim_weighted:\n",
    "        journ_name = train_y[doc_id] # 저널명 가져오기\n",
    "        # sum_dict[journ_name] += sim_score\n",
    "        sum_dict[journ_name].append(sim_score) # 저널별 유사도 점수 합치기\n",
    "    \n",
    "    mean_dict = {key: np.mean(values) for key, values in sum_dict.items()}\n",
    "    \n",
    "    # 총 유사도 점수가 높은 순서대로 저널 이름 정렬 (S-Sort)\n",
    "    journ_sorted = list(dict(sorted(mean_dict.items(), key=itemgetter(1), reverse=True)).keys())\n",
    "    \n",
    "    return journ_sorted\n",
    "\n",
    "# 추천 후보 저널 - list of journals (R)\n",
    "workers = os.cpu_count() * 2\n",
    "with parallel_backend(backend='loky', n_jobs=workers):\n",
    "    r = list(Parallel()(delayed(get_all_sim_journ)(doc_sims) for doc_sims in tqdm(s1, position=0, leave=True)))\n",
    "\n",
    "print(len(r))\n",
    "print(r[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c1045742-f6cf-4a0c-b9d7-ff18d2ebff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 유사도 높은 journal 리스트 pickle로 저장\n",
    "# with open('./data/r_exp_weighted.pkl', 'wb') as f:\n",
    "#     pickle.dump(r, f)\n",
    "\n",
    "# 저장한 pickle 다시 읽기\n",
    "# with open('./data/r_exp_weighted.pkl', 'rb') as f:\n",
    "#     r = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b1d1b-8875-4425-b4e6-7ff82aa0471d",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "# # Phase 2: 후보 저널 재정렬\n",
    "- 후보 저널 재정렬\n",
    "    - 입력 문서 vs. 저널의 Title, Keyword 유사도 기반 (S2+S3)\n",
    "    - 초록 외 키워느나 제목이 입력된 경우, 저널에 출판된 문서들(train)의 키워드와 일치도를 계산하여 추천 결과를 개선하기 위한 과정\n",
    "    - 후보 저널 리스트업 된 것에 순위 sort하기 위한 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672871d8-4ead-4e3e-b214-3b43cdd9678d",
   "metadata": {},
   "source": [
    "## 문서 vs. 저널 유사도 (S2+S3)\n",
    "- Keyword 유사도 (S2) + Title 유사도 (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6c9e1-7ac3-4b78-abcc-ef1032b51d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10307,)\n",
      "(10307, 135402)\n",
      "(10307, 268)\n",
      "(10307,)\n",
      "(10307, 43041)\n",
      "(10307, 268)\n",
      "(10307, 268)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.16510017, 0.09318388, 0.07643517, ..., 0.03647989, 0.12525107,\n",
       "        0.07358115],\n",
       "       [0.        , 0.        , 0.        , ..., 0.0032244 , 0.00759136,\n",
       "        0.00520297],\n",
       "       [0.1249516 , 0.06112054, 0.05013484, ..., 0.19781094, 0.13443356,\n",
       "        0.11188206],\n",
       "       [0.        , 0.        , 0.        , ..., 0.03224398, 0.01180878,\n",
       "        0.00346865],\n",
       "       [0.11973687, 0.12910096, 0.07206377, ..., 0.17196787, 0.17375783,\n",
       "        0.1314451 ]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ================================================= #\n",
    "# test document vs. train journal의 keyword 유사도 구하기 (S2)\n",
    "\n",
    "# 각 Test 데이터의 문서별 Keyword Matrix 생성 (Test JKM)\n",
    "test_doc_kw = test['keyword']\n",
    "print(test_doc_kw.shape)\n",
    "\n",
    "# document-keyword matrix 생성 (JKM 생성때 fit된 count vectorizer 사용)\n",
    "test_doc_kw_mat = count_vect_kw.transform(test_doc_kw)\n",
    "print(test_doc_kw_mat.shape)\n",
    "\n",
    "# dataframe 형태로 확인\n",
    "# d_kw_df = pd.DataFrame(d_kw_mat.toarray(), index=d_kw.index, columns=count_vect_kw.get_feature_names_out())\n",
    "\n",
    "# keyword 사이의 document vs. journal 유사도 계산\n",
    "s2 = cosine_similarity(test_doc_kw_mat, jkm)\n",
    "print(s2.shape)\n",
    "\n",
    "# ================================================= #\n",
    "# test document vs. train journal의 title 유사도 구하기 (S3)\n",
    "\n",
    "# 각 Test 데이터의 문서별 Title Matrix 생성 (Test JTM)\n",
    "test_doc_tt = test['title_nn']\n",
    "print(test_doc_tt.shape)\n",
    "\n",
    "# document-title matrix 생성 (JTM 생성때 fit된 count vectorizer 사용)\n",
    "test_doc_tt_mat = count_vect_tt.transform(test_doc_tt)\n",
    "print(test_doc_tt_mat.shape)\n",
    "\n",
    "# dataframe 형태로 확인\n",
    "# d_tt_df = pd.DataFrame(d_tt_mat.toarray(), index=d_tt.index, columns=count_vect_tt.get_feature_names_out())\n",
    "\n",
    "# title 사이의 document vs. journal 유사도 계산\n",
    "s3 = cosine_similarity(test_doc_tt_mat, jtm)\n",
    "print(s3.shape)\n",
    "\n",
    "# ================================================= #\n",
    "# Title 코사인 유사도 + Keyword 코사인 유사도 더하기 (S2+S3)\n",
    "s23 = s2 + s3\n",
    "print(s23.shape)\n",
    "s23[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da6c1e-ec0f-4bfa-9a1a-6fa92f38a31f",
   "metadata": {},
   "source": [
    "## 추천 저널 리스트 재배치\n",
    "\n",
    "**Note: 코드가 실행되는 곳은 아래 \"Phase\"의 모델링 부분에서 실행 됨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ecd83-0c12-4f11-9f79-eb6377c2ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 vs. 저널 유사도(S2+S3)에 따른 후보 저널 재배치\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "# def resort_r(tt_kw_s, i):\n",
    "#     # doc-journal별 유사도 점수에 journal 이름 붙이기 \n",
    "#     journ_scores = list(zip(journ_index.index, tt_kw_s[i])) # journal 이름 붙이기\n",
    "#     # 높은 유사도순으로 journal 정렬\n",
    "#     journ_scores_sorted = sorted(journ_scores, key=lambda x: x[1], reverse=True) \n",
    "#     # journal이 기존 list of journals에 있는 journal이라면 포함 (정렬된 순서에 맞춰 새로운 R 생성)\n",
    "#     journ_filtered = [journ for journ, sim in journ_scores_sorted if journ in top_k_journs[i]]\n",
    "#     return journ_filtered\n",
    "\n",
    "def resort_r(tt_kw_s, top_k_journs, i):\n",
    "    # 각 doc의 journal별 title+keyword 유사도 점수에 journal 이름 붙이기 \n",
    "    journ_scores = dict(zip(journ_index.index, tt_kw_s[i])) # journal 이름 붙이기\n",
    "    # 높은 유사도순으로 journal 재배치 (기존 list of journals에 있는 저널만 포함) -> 새로운 R 생성\n",
    "    journ_sorted = list(dict(sorted(filter(lambda x: x[0] in top_k_journs[i], journ_scores.items()), key=itemgetter(1), reverse=True)).keys())\n",
    "    return journ_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c81b93-7d86-48ed-bf2e-b2b010b40ab7",
   "metadata": {},
   "source": [
    "---\n",
    "# # Phase 3: 후보 저널 추가\n",
    "- Test 데이터셋 사용\n",
    "- 후보 저널 추가\n",
    "    - 저널 vs. 저널 유사도 (S4) 기반\n",
    "    - Title, Keyword 유사도\n",
    "    - 새로 추가할 수 있는, 상위 후보 저널과 유사한 후보 저널을 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee3bb5-267d-473b-b8ef-33f7968214cc",
   "metadata": {},
   "source": [
    "## 저널 vs. 저널 유사도 (S4) | 후보 저널 추가\n",
    "\n",
    "**Note: 코드가 실행되는 곳은 아래 \"Phase\"의 모델링 부분에서 실행 됨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "951acbfb-b2a9-4a62-8f8a-5b3c723201aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "# 저널 vs. 저널 유사도 (S4) 계산 및 후보 저널 추가\n",
    "def find_other_sim_journ(cur_top_journs):\n",
    "    '''\n",
    "    # Description :\n",
    "    # 추천 저널 후보 리스트에서, 맨 앞의 최상위 저널(R1) 1개에 대해 저널들과의 유사도를 분석 (저널 vs. 저널 유사도 분석)\n",
    "    # 이후, 유사도 높은 저널부터 순차적으로 추천 저널 후보 리스트에 없는 저널을 찾기\n",
    "    # 만약 찾았지만, 발견한 저널의 유사도 점수가 0보다 크지 않다면 (그 뒤 후보들의 유사도는 볼 필요 없이)\n",
    "    # R1은 pass하고 다음 상위 저널(R2, R3, ... 순차적으로)로 같은 방법으로 탐색\n",
    "    '''\n",
    "    def if_not_in_r(x):\n",
    "        # list of journals에 이미 있는지/없는지 확인\n",
    "        if x[0] in cur_top_journs:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    # list of journals이 애초에 비어있는 경우\n",
    "    if not len(cur_top_journs):\n",
    "        # 빈 list of journals 그대로 반환\n",
    "        return cur_top_journs\n",
    "    \n",
    "    # 추가 후보 저널 탐색\n",
    "    add_journ_found = False\n",
    "    for i in range(len(cur_top_journs)):\n",
    "        # 현재 선택된 상위 저널\n",
    "        best_journ = cur_top_journs[i] # 맨 앞의(최상위) 후보 저널부터 하나씩\n",
    "\n",
    "        # # 해당 상위 저널과 다른 저널들의 title 유사도 구하기\n",
    "        # best_j_tt = train[train['journal'] == best_journ].groupby('journal')['title_nn'].apply(' '.join) # 해당 상위 저널의 (모든 doc의) 전처리된 title text 모으기\n",
    "        # best_j_tt_mat = count_vect_tt.transform(best_j_tt) # 상위 저널의 journal-title matrix 생성 (train JTM 생성시 fit한 count vectorizer로 transform)\n",
    "        best_j_tt_mat = jtm[journ_index[best_journ]]\n",
    "        best_tt_sim = cosine_similarity(best_j_tt_mat, jtm) # 상위 저널 JTM - train JTM 과의 title 코사인 유사도 (1, 268)\n",
    "\n",
    "        # 해당 상위 저널과 다른 후보 저널들의 keyword 유사도 구하기\n",
    "        # best_j_kw = train[train['journal'] == best_journ].groupby('journal')['keyword'].apply(' '.join) # 해당 상위 저널의 (모든 doc의) 전처리된 keyword text 모으기\n",
    "        # best_j_kw_mat = count_vect_kw.transform(best_j_kw) # 상위 저널의 journal-keyword matrix 생성 (train JKM 생성시 fit한 count vectorizer로 transform)\n",
    "        best_j_kw_mat = jkm[journ_index[best_journ]]\n",
    "        best_kw_sim = cosine_similarity(best_j_kw_mat, jkm) # 상위 저널 JKM - train JKM 과의 keyword 코사인 유사도\n",
    "\n",
    "        # 해당 후보 저널의 다른 저널들과의 최종 유사도 구하기\n",
    "        s4 = best_tt_sim + best_kw_sim # Title 코사인 유사도 + Keyword 코사인 유사도 더하기\n",
    "        s4 = s4[0] # 268개 각 저널별 유사도 점수; test document 1개씩 처리 중이기 때문에 [i]가 아닌 [0] indexing\n",
    "        \n",
    "        # 높은 유사도 순으로 후보 저널 정렬0\n",
    "        best_jj_sim = sorted(dict(zip(journ_index.index, s4)).items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "        # 그 중 기존 list of journals에 없는 저널 탐색 (유사도 높은 후보부터)\n",
    "        new_journ_found = next(filter(if_not_in_r, best_jj_sim), None)\n",
    "        if new_journ_found != None: # list of journals에 없는 후보 저널 1개를 찾았고,\n",
    "            if new_journ_found[1] > 0: # 해당 저널의 유사도 점수가 0보다 크다면\n",
    "                # 후보 저널 추가\n",
    "                top_journs_added = cur_top_journs + [new_journ_found[0]] # list of journals에 추가\n",
    "                add_journ_found = True\n",
    "                return top_journs_added\n",
    "            else: # 유사도 점수가 0이면, 다음 후보 저널로 탐색 (R2,R3,...)\n",
    "                continue\n",
    "        else: # list of journals에 없는 후보 저널이 없다면(모든 후보 저널이 이미 다 list of journals에 있다면)\n",
    "            continue # 다음 후보 저널로 탐색 (R2,R3,...)\n",
    "    \n",
    "    # 모든 후보 저널을(R1,R2,R3,...) 다 탐색했지만, 적합한 후보 저널을 못 찾았다면\n",
    "    if not add_journ_found:\n",
    "        top_journs_added = cur_top_journs # 기존 list of journals 그대로 사용\n",
    "        return top_journs_added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112aa251-ad78-4c98-aa18-8b4663a0431e",
   "metadata": {},
   "source": [
    "# # 모델링 및 평가\n",
    "- Best model 사용\n",
    "- Top-K 저널 추천 및 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733737c3-66e5-41ac-87d7-5eaa78e23b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 모델 평가 지표 함수\n",
    "\n",
    "# Micro Accuracy\n",
    "def get_acc_micro(y_pred, y_true):\n",
    "    return np.mean(np.array([1 if y_true[i] in y_pred[i] else 0 for i in range(len(y_true))])) \n",
    "\n",
    "# Macro Accuracy\n",
    "def get_acc_macro(y_pred, y_true):\n",
    "    global each_journ_ox, each_journ_mean_acc\n",
    "    # 저널별로 맞은 것은 1, 틀린 것은 0으로 넣기\n",
    "    each_journ_ox = collections.defaultdict(list)\n",
    "    for journ_actual, journs_rec in list(zip(y_true, y_pred)):\n",
    "        if journ_actual in journs_rec:\n",
    "            each_journ_ox[journ_actual].append(1)\n",
    "        else:\n",
    "            each_journ_ox[journ_actual].append(0)\n",
    "    # 저널별 평균 accuracy 계산\n",
    "    each_journ_mean_acc = {key: np.mean(values) for key, values in each_journ_ox.items()} # dictionary comprehension\n",
    "    # 저널별 평균 accuracy의 전체 평균 계산\n",
    "    mean_of_mean_acc = np.mean(list(each_journ_mean_acc.values()))\n",
    "    return mean_of_mean_acc\n",
    "\n",
    "# MRR\n",
    "def get_mrr(y_pred, y_true):\n",
    "    # 각 예측별 reciprocal rank 구하기 (실제 저널이 추천 리스트에서 몇 번째에 위치하는지)\n",
    "    recip_rank_computed = []\n",
    "    for journ_actual, journs_rec in list(zip(y_true, y_pred)):\n",
    "        try:\n",
    "            # 추천 리스트에 있다면, 위치 번호에 역수 취하기 (앞에 나올수록 좋은 모델이니까)\n",
    "            recip_rank = 1 / (journs_rec.index(journ_actual) + 1) # 1/(index + 1)\n",
    "        except:\n",
    "            # 추천 리스트에 없다면 0\n",
    "            recip_rank = 0\n",
    "        recip_rank_computed.append(recip_rank)\n",
    "    # Mean Reciprocal Rank 계산\n",
    "    mmr = np.mean(recip_rank_computed)\n",
    "    return mmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "1a60310a-07ef-46c3-a897-b73ace564c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 저널 수(K) 설정\n",
    "# Top-3, Top-5, Top-10, Top-15, Top-20\n",
    "\n",
    "K_list = [3, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33189be-0b90-4fa7-9547-4fd2457bd999",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Phase 1: Abs\n",
    "- 바로 Top-K 저널 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7964d677-366f-4e3c-a1a2-b3c3b9fef32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n",
      "Current K: 5\n",
      "Current K: 10\n",
      "Current K: 15\n",
      "Current K: 20\n",
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
      "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
      "mrr       0.3879 0.4144  0.4305  0.4355  0.4376\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.8073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.3879</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>0.4305</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>0.4376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
       "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
       "mrr       0.3879 0.4144  0.4305  0.4355  0.4376"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title and/or Keyword 여부에 따른 설정\n",
    "tt_kw_exist = False\n",
    "tt_kw_s = None\n",
    "\n",
    "accuracy_results = pd.DataFrame()\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K\n",
    "    first_n = K\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs.tolist()\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    # workers = -1\n",
    "    # with parallel_backend(backend='threading', n_jobs=workers):\n",
    "    #     top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    top_k_r = r_resort\n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_1 = accuracy_results.copy()\n",
    "print(acc_abstr_1)\n",
    "acc_abstr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0f203c29-3e57-4c0d-9bc6-f74e20527458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_1.to_csv('./acc_model4/acc_abstr_1.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_1 = pd.read_csv('./acc_model4/acc_abstr_1.csv', index_col=0)\n",
    "# acc_abstr_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac91f32-4816-437a-9979-b086a083c55c",
   "metadata": {},
   "source": [
    "## Phase 1+2: Abs + Kw\n",
    "- Top-K 저널 추출 후, 저널 재배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d0a85c83-f3c0-4235-b894-c546b36bac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:03<00:00, 2594.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2573.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:03<00:00, 2590.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2548.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2509.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
      "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
      "mrr       0.4018 0.4327  0.4379  0.4327  0.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.8073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.4018</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.4261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
       "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
       "mrr       0.4018 0.4327  0.4379  0.4327  0.4261"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title and/or Keyword 여부에 따른 설정\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s2\n",
    "\n",
    "accuracy_results = pd.DataFrame()\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K\n",
    "    first_n = K\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs.tolist()\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    # workers = -1\n",
    "    # with parallel_backend(backend='threading', n_jobs=workers):\n",
    "    #     top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    top_k_r = r_resort\n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_kw_1_2 = accuracy_results.copy()\n",
    "print(acc_abstr_kw_1_2)\n",
    "acc_abstr_kw_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ce344535-f75f-470c-b0eb-f52bda25b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_kw_1_2.to_csv('./acc_model4/acc_abstr_kw_1_2.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_kw_1_2 = pd.read_csv('./acc_model4/acc_abstr_kw_1_2.csv', index_col=0)\n",
    "# acc_abstr_kw_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9320e7-31d5-41c1-88c6-cb18439b0a11",
   "metadata": {},
   "source": [
    "## Phase 1+2: Abs + Tt\n",
    "- Top-K 저널 추출 후, 저널 재배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2c977b02-ec17-4adf-885d-ab496facc833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:03<00:00, 2637.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:03<00:00, 2628.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:03<00:00, 2589.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2567.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2548.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
      "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
      "mrr       0.3982 0.4270  0.4237  0.4124  0.4028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.8073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.3982</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.4237</td>\n",
       "      <td>0.4124</td>\n",
       "      <td>0.4028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
       "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
       "mrr       0.3982 0.4270  0.4237  0.4124  0.4028"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title and/or Keyword 여부에 따른 설정\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s3\n",
    "\n",
    "accuracy_results = pd.DataFrame()\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K\n",
    "    first_n = K\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs.tolist()\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    # workers = -1\n",
    "    # with parallel_backend(backend='threading', n_jobs=workers):\n",
    "    #     top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    top_k_r = r_resort\n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_tt_1_2 = accuracy_results.copy()\n",
    "print(acc_abstr_tt_1_2)\n",
    "acc_abstr_tt_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "32521992-01d7-471f-b05e-f9231cba70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_tt_1_2.to_csv('./acc_model4/acc_abstr_tt_1_2.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_tt_1_2 = pd.read_csv('./acc_model4/acc_abstr_tt_1_2.csv', index_col=0)\n",
    "# acc_abstr_tt_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31b501-c3b0-4113-8720-36a4b1d3f3c3",
   "metadata": {},
   "source": [
    "## Phase 1+2: Abs + Tt + Kw\n",
    "- Top-K 저널 추출 후, 저널 재배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fcae7ad4-c5f3-4955-800f-eb37f9ac713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:03<00:00, 2582.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:03<00:00, 2602.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2576.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2571.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2563.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
      "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
      "mrr       0.4095 0.4466  0.4602  0.4574  0.4538\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4332</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.8073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.4095</td>\n",
       "      <td>0.4466</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.4538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.5195 0.6356  0.7541  0.8167  0.8546\n",
       "macro_acc 0.4332 0.5544  0.6803  0.7532  0.8073\n",
       "mrr       0.4095 0.4466  0.4602  0.4574  0.4538"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title and/or Keyword 여부에 따른 설정\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s23\n",
    "\n",
    "accuracy_results = pd.DataFrame()\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K\n",
    "    first_n = K\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs.tolist()\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    # workers = -1\n",
    "    # with parallel_backend(backend='threading', n_jobs=workers):\n",
    "    #     top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    top_k_r = r_resort\n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_tt_kw_1_2 = accuracy_results.copy()\n",
    "print(acc_abstr_tt_kw_1_2)\n",
    "acc_abstr_tt_kw_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d7fb424a-3195-473c-b45a-f083751e2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_tt_kw_1_2.to_csv('./acc_model4/acc_abstr_tt_kw_1_2.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_tt_kw_1_2 = pd.read_csv('./acc_model4/acc_abstr_tt_kw_1_2.csv', index_col=0)\n",
    "# acc_abstr_tt_kw_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613717df-22b0-4fe1-9c3d-ca3ac6dae1a6",
   "metadata": {},
   "source": [
    "## Phase 1+3: Abs\n",
    "- Top-(K-1) 저널 추출 후, 유사 저널 1개 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "039318c2-2800-463e-ac40-67987bc93b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10307/10307 [00:39<00:00, 261.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 296.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10307/10307 [00:36<00:00, 284.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10307/10307 [00:39<00:00, 263.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10307/10307 [00:39<00:00, 262.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.4837 0.6185  0.7587  0.8211  0.8590\n",
      "macro_acc 0.3961 0.5275  0.6775  0.7549  0.8086\n",
      "mrr       0.3759 0.4110  0.4310  0.4358  0.4379\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.4837</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.3961</td>\n",
       "      <td>0.5275</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.8086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.3759</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.4379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.4837 0.6185  0.7587  0.8211  0.8590\n",
       "macro_acc 0.3961 0.5275  0.6775  0.7549  0.8086\n",
       "mrr       0.3759 0.4110  0.4310  0.4358  0.4379"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title and/or Keyword 여부에 따른 설정\n",
    "tt_kw_exist = False\n",
    "tt_kw_s = None\n",
    "\n",
    "accuracy_results = pd.DataFrame()\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K-1\n",
    "    first_n = K-1\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs.tolist()\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    workers = -1\n",
    "    with parallel_backend(backend='threading', n_jobs=workers):\n",
    "        top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_1_3 = accuracy_results.copy()\n",
    "print(acc_abstr_1_3)\n",
    "acc_abstr_1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "b54ab1b4-5914-4c91-91a9-861139abd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_1_3.to_csv('./acc_model4/acc_abstr_1_3.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_1_3 = pd.read_csv('./acc_model4/acc_abstr_1_3.csv', index_col=0)\n",
    "# acc_abstr_1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a36f7-51f6-411e-b864-dfd23355d4a7",
   "metadata": {},
   "source": [
    "## Phase 1+2+3: Abs + Kw\n",
    "- Top-(K-1) 저널 추출 후, 유사 저널 1개 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e0e73204-9197-4873-bc52-163546b7231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2510.62it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:37<00:00, 271.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2497.76it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 299.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2152.23it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 299.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2442.88it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 301.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2472.06it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 301.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.4950 0.6316  0.7650  0.8275  0.8647\n",
      "macro_acc 0.4093 0.5411  0.6882  0.7602  0.8142\n",
      "mrr       0.3864 0.4309  0.4420  0.4359  0.4285\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.8647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4093</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.6882</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.8142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>0.4359</td>\n",
       "      <td>0.4285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.4950 0.6316  0.7650  0.8275  0.8647\n",
       "macro_acc 0.4093 0.5411  0.6882  0.7602  0.8142\n",
       "mrr       0.3864 0.4309  0.4420  0.4359  0.4285"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title and/or Keyword 여부에 따른 설정\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s2\n",
    "\n",
    "accuracy_results = pd.DataFrame()\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K-1\n",
    "    first_n = K-1\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs.tolist()\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    workers = -1\n",
    "    with parallel_backend(backend='threading', n_jobs=workers):\n",
    "        top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_kw_1_2_3 = accuracy_results.copy()\n",
    "print(acc_abstr_kw_1_2_3)\n",
    "acc_abstr_kw_1_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "6f32f290-e577-4598-bd83-0c02dd7f56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_kw_1_2_3.to_csv('./acc_model4/acc_abstr_kw_1_2_3.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_kw_1_2_3 = pd.read_csv('./acc_model4/acc_abstr_kw_1_2_3.csv', index_col=0)\n",
    "# acc_abstr_kw_1_2_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5bae87-4e61-43dd-9266-ede70d7a745f",
   "metadata": {},
   "source": [
    "## Phase 1+2+3: Abs + Tt\n",
    "- Top-(K-1) 저널 추출 후, 유사 저널 1개 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f71438c3-bb4e-4cbd-bd46-06c68c6cd9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2512.09it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 294.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2532.99it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 296.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2527.28it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 296.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2480.68it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 294.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2374.06it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:34<00:00, 296.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.4944 0.6306  0.7637  0.8256  0.8615\n",
      "macro_acc 0.4093 0.5390  0.6852  0.7584  0.8095\n",
      "mrr       0.3855 0.4252  0.4289  0.4158  0.4056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.6306</td>\n",
       "      <td>0.7637</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4093</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.7584</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.4252</td>\n",
       "      <td>0.4289</td>\n",
       "      <td>0.4158</td>\n",
       "      <td>0.4056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.4944 0.6306  0.7637  0.8256  0.8615\n",
       "macro_acc 0.4093 0.5390  0.6852  0.7584  0.8095\n",
       "mrr       0.3855 0.4252  0.4289  0.4158  0.4056"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title and/or Keyword 여부에 따른 설정\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s3\n",
    "\n",
    "accuracy_results = pd.DataFrame()\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K-1\n",
    "    first_n = K-1\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs.tolist()\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    workers = -1\n",
    "    with parallel_backend(backend='threading', n_jobs=workers):\n",
    "        top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_tt_1_2_3 = accuracy_results.copy()\n",
    "print(acc_abstr_tt_1_2_3)\n",
    "acc_abstr_tt_1_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "739e58ec-4687-4abe-9819-711c47d98e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_tt_1_2_3.to_csv('./acc_model4/acc_abstr_tt_1_2_3.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_tt_1_2_3 = pd.read_csv('./acc_model4/acc_abstr_tt_1_2_3.csv', index_col=0)\n",
    "# acc_abstr_tt_1_2_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5248089f-db11-4455-a664-b541d6867e6d",
   "metadata": {},
   "source": [
    "## Phase 1+2+3: Abs + Tt + Kw\n",
    "- Top-(K-1) 저널 추출 후, 유사 저널 1개 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "71f3233f-d6f5-4e72-8d9f-9545bab8ef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2554.85it/s]\n",
      "100%|█████████████████████████████████████| 10307/10307 [02:54<00:00, 58.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2460.12it/s]\n",
      "100%|█████████████████████████████████████| 10307/10307 [02:32<00:00, 67.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2518.62it/s]\n",
      "100%|█████████████████████████████████████| 10307/10307 [02:20<00:00, 73.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2468.87it/s]\n",
      "100%|█████████████████████████████████████| 10307/10307 [02:13<00:00, 76.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2468.46it/s]\n",
      "100%|█████████████████████████████████████| 10307/10307 [02:11<00:00, 78.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-10</th>\n",
       "      <th>Top-15</th>\n",
       "      <th>Top-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro_acc</th>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.8644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_acc</th>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.8143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr</th>\n",
       "      <td>0.3906</td>\n",
       "      <td>0.4411</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>0.4591</td>\n",
       "      <td>0.4556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
       "micro_acc 0.4948 0.6319  0.7657  0.8270  0.8644\n",
       "macro_acc 0.4091 0.5411  0.6886  0.7601  0.8143\n",
       "mrr       0.3906 0.4411  0.4630  0.4591  0.4556"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 모델에서 sum이 아닌 mean 사용한 모델 평가\n",
    "# 1) 모든 유사도에 대한 mean (O)\n",
    "\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s23\n",
    "\n",
    "accuracy_results = pd.DataFrame() # 정확도 결과 df\n",
    "\n",
    "for K in K_list:\n",
    "    print('Current K:', K)\n",
    "    \n",
    "    ## (1차) Test document별 Top-(K-1) 저널\n",
    "    # Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "    # 1차에서 찾을 추천 후보 저널 수: K-1\n",
    "    first_n = K-1\n",
    "    top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "    ## (2차) R-resort : List of Journals 재배치\n",
    "    # Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "    if tt_kw_exist:\n",
    "        r_resort = list()\n",
    "        for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "            r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "    # 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "    else:\n",
    "        r_resort = top_k_journs\n",
    "\n",
    "    ## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "    #workers = os.cpu_count() * 2\n",
    "    workers = -1\n",
    "    with parallel_backend(backend='threading', n_jobs=workers):\n",
    "        top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    \n",
    "    \n",
    "    ## 정확도 평가\n",
    "    micro_acc = get_acc_micro(top_k_r, test_y) # Top-K Micro Accuracy (전체 Accuracy 합계 / 전체 N)\n",
    "    macro_acc = get_acc_macro(top_k_r, test_y) # Top-K Macro Accuracy (저널별 평균 accuracy의 평균)\n",
    "    mrr = get_mrr(top_k_r, test_y) # Top-K MRR (실제 저널이 추천 저널 리스트에 있다면 해당 순위를 반영해 점수 계산)\n",
    "    top_k_eval = pd.DataFrame([micro_acc, macro_acc, mrr], index=['micro_acc', 'macro_acc', 'mrr'], columns=[f'Top-{K}'])\n",
    "    \n",
    "    accuracy_results = pd.concat([accuracy_results,top_k_eval], axis=1)\n",
    "    \n",
    "acc_abstr_tt_kw_1_2_3 = accuracy_results.copy()\n",
    "print(acc_abstr_tt_kw_1_2_3)\n",
    "acc_abstr_tt_kw_1_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "fc9d4073-c958-46f4-b4d5-a2bc88400585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Top-3  Top-5  Top-10  Top-15  Top-20\n",
      "micro_acc 0.4948 0.6319  0.7657  0.8270  0.8644\n",
      "macro_acc 0.4091 0.5411  0.6886  0.7601  0.8143\n",
      "mrr       0.3906 0.4411  0.4630  0.4591  0.4556\n"
     ]
    }
   ],
   "source": [
    "print(acc_abstr_tt_kw_1_2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0b7b5c12-8acc-4aa8-a12a-1b616b300c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 결과 csv 저장\n",
    "acc_abstr_tt_kw_1_2_3.to_csv('./acc_model4/acc_abstr_tt_kw_1_2_3.csv', index=True)\n",
    "\n",
    "# 결과 csv 다시 읽기\n",
    "# acc_abstr_tt_kw_1_2_3 = pd.read_csv('./acc_model4/acc_abstr_tt_kw_1_2_3.csv', index_col=0)\n",
    "# acc_abstr_tt_kw_1_2_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a0c27-5494-4c9c-a50d-2764447bbca0",
   "metadata": {},
   "source": [
    "# # 사용자 평가용 Top-5 저널 출력\n",
    "- 최종 프레임워크의 Top-5 추천 저널에 대한 사용자 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad69ba6-c8aa-4f21-9714-99c463ce3299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current K: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10307/10307 [00:04<00:00, 2503.56it/s]\n",
      "100%|████████████████████████████████████| 10307/10307 [00:33<00:00, 303.39it/s]\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "\n",
    "tt_kw_exist = True\n",
    "tt_kw_s = s23\n",
    "\n",
    "print('Current K:', K)\n",
    "\n",
    "## (1차) Test document별 Top-(K-1) 저널\n",
    "# Abstract에 대한 doc-to-doc 유사도 합계가 높은 순서로 저널 정렬됨\n",
    "# 1차에서 찾을 추천 후보 저널 수: K-1\n",
    "first_n = K-1\n",
    "top_k_journs = np.array(r)[:, :first_n]\n",
    "\n",
    "## (2차) R-resort : List of Journals 재배치\n",
    "# Title and/or keyword가 있다면, test doc vs. train journ의 Title 및 Keyword 유사도 높은 순서로 재정렬\n",
    "if tt_kw_exist:\n",
    "    r_resort = list()\n",
    "    for i in tqdm(range(len(tt_kw_s)), position=0, leave=True): # 10307\n",
    "        r_resort.append(resort_r(tt_kw_s, top_k_journs, i))\n",
    "# 없다면, Abstract 유사도 기준으로 정렬된 1차 추천 후보 리스트 그대로 사용\n",
    "else:\n",
    "    r_resort = top_k_journs\n",
    "\n",
    "## (3차) 상위 1개 journal-journal 유사도 분석 및 추가 할 수 있는 후보 저널 탐색\n",
    "#workers = os.cpu_count() * 2\n",
    "workers = -1\n",
    "with parallel_backend(backend='threading', n_jobs=workers):\n",
    "    top_k_r = list(Parallel()(delayed(find_other_sim_journ)(top_journs_list) for top_journs_list in tqdm(r_resort, position=0, leave=True)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d66c5-1d6d-41ca-8358-37fda006f19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>초록</th>\n",
       "      <th>저널</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>R4</th>\n",
       "      <th>R5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>충북지역 포도원 잡초방제별 생육 및 수량에 미치는 영향</td>\n",
       "      <td>본 시험은 충북지역 포도원 잡초방제별 생육 및 수량에 미치는 영향을 구명하기 위해 ...</td>\n",
       "      <td>농약과학회지</td>\n",
       "      <td>시설원예ㆍ식물공장</td>\n",
       "      <td>원예과학기술지</td>\n",
       "      <td>한국가금학회지</td>\n",
       "      <td>한국응용곤충학회지</td>\n",
       "      <td>농업과학연구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다중 추적자 영상을 위한 컴프턴 카메라</td>\n",
       "      <td>컴프턴 산란 현상을 이용하여 전자적 집속 방법으로 영상화하는 컴프턴카메라는 고민감도...</td>\n",
       "      <td>한국의학물리학회지:의학물리</td>\n",
       "      <td>한국의학물리학회지:의학물리</td>\n",
       "      <td>한국방사선학회논문지</td>\n",
       "      <td>한국정보통신학회논문지</td>\n",
       "      <td>한국음향학회지</td>\n",
       "      <td>대한방사선치료학회지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>언어적인 항해안전정보 지원을 위한 의미해석 모델 구축에 관한 연구</td>\n",
       "      <td>선박의 항해사가 안전 항해를 위해 GPS, ARPA, AIS, NAVTEX, VHF...</td>\n",
       "      <td>한국지능시스템학회논문지</td>\n",
       "      <td>한국항해항만학회지</td>\n",
       "      <td>디지털콘텐츠학회 논문지</td>\n",
       "      <td>한국정보통신학회논문지</td>\n",
       "      <td>한국지능시스템학회논문지</td>\n",
       "      <td>해양환경안전학회지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>홍천 철-희토류 광상의 편마암질 주변암에 대한 SHRIMP U-Pb 연령측정</td>\n",
       "      <td>홍천에는 카보내타이트-포스코라이트 복합체로 구성된 철-희토류 광상이 분포한다. 이 ...</td>\n",
       "      <td>암석학회지</td>\n",
       "      <td>암석학회지</td>\n",
       "      <td>자원환경지질</td>\n",
       "      <td>한국광물학회지</td>\n",
       "      <td>한국제4기학회지</td>\n",
       "      <td>한국지구과학회지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>중소기업의 FTA 특혜활용을 위한 HS 품목분류 자가결정 방법에 대한 연구</td>\n",
       "      <td>FTA가 확대됨에 따라 FTA별로 상이한 원산지결정기준을 활용한 특혜 수혜가 점차 ...</td>\n",
       "      <td>통상정보연구</td>\n",
       "      <td>통상정보연구</td>\n",
       "      <td>한국항만경제학회지</td>\n",
       "      <td>유통과학연구</td>\n",
       "      <td>한국유통학회지:유통연구</td>\n",
       "      <td>경영과정보연구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>가공된 순환자원을 시멘트 혼화재로 활용한 흙 시멘트 공시체의 강도 특성에 관한 연구</td>\n",
       "      <td>본 연구에서는 소성 굴패각, 비소성 굴패각, 자력선별된 전로 제강슬래그와 Fly a...</td>\n",
       "      <td>터널과지하공간</td>\n",
       "      <td>한국건설순환자원학회논문집</td>\n",
       "      <td>한국구조물진단유지관리공학회 논문집</td>\n",
       "      <td>한국콘크리트학회논문집</td>\n",
       "      <td>대한토목학회논문집</td>\n",
       "      <td>한국건축시공학회지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>E-Shape 강재이력댐퍼의 수치모델과 기초격리구조물의 지진응답</td>\n",
       "      <td>최근 대규모의 지진피해로 인해 내진설계에 대한 관심이 높아지면서, LRB(Lead ...</td>\n",
       "      <td>대한토목학회논문집</td>\n",
       "      <td>한국전산구조공학회논문집</td>\n",
       "      <td>대한토목학회논문집</td>\n",
       "      <td>한국구조물진단유지관리공학회 논문집</td>\n",
       "      <td>한국콘크리트학회논문집</td>\n",
       "      <td>대한기계학회논문집A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304</th>\n",
       "      <td>초등학교 5학년 영어 교과서 분석: 어휘학습전략 중심으로</td>\n",
       "      <td>최근 외국어 학습에 있어 어휘 학습의 중요성이 부각되며 어휘학습전략 교육에 대한 관...</td>\n",
       "      <td>한국콘텐츠학회논문지</td>\n",
       "      <td>한국초등수학교육학회지</td>\n",
       "      <td>대한수학교육학회지:수학교육학연구</td>\n",
       "      <td>한국학교수학회논문집</td>\n",
       "      <td>한국콘텐츠학회논문지</td>\n",
       "      <td>한국수학교육학회지시리즈C:초등수학교육</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>도계 후 원료육의 저장기간 동안 가슴육의 품질 특성</td>\n",
       "      <td>본 연구는 도계 후 원료육의 저장기간에 따른 품질 특성을 조사하여 가공업소에서 반입...</td>\n",
       "      <td>한국가금학회지</td>\n",
       "      <td>원예과학기술지</td>\n",
       "      <td>한국가금학회지</td>\n",
       "      <td>시설원예ㆍ식물공장</td>\n",
       "      <td>대한환경공학회지</td>\n",
       "      <td>농업과학연구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>JMP+RAND: 바이너리 난수 삽입을 통한 메모리 공유 기반 부채널 공격 방어 기법</td>\n",
       "      <td>컴퓨터가 보급된 이래로 정보보안을 달성하기 위해 많은 노력이 이루어졌다. 그중 메모...</td>\n",
       "      <td>정보처리학회논문지:컴퓨터 및 통신 시스템</td>\n",
       "      <td>정보처리학회논문지:컴퓨터 및 통신 시스템</td>\n",
       "      <td>한국컴퓨터정보학회논문지</td>\n",
       "      <td>정보처리학회논문지C</td>\n",
       "      <td>한국정보통신학회논문지</td>\n",
       "      <td>인터넷정보학회논문지</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10307 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    제목  \\\n",
       "0                       충북지역 포도원 잡초방제별 생육 및 수량에 미치는 영향   \n",
       "1                                다중 추적자 영상을 위한 컴프턴 카메라   \n",
       "2                 언어적인 항해안전정보 지원을 위한 의미해석 모델 구축에 관한 연구   \n",
       "3           홍천 철-희토류 광상의 편마암질 주변암에 대한 SHRIMP U-Pb 연령측정   \n",
       "4            중소기업의 FTA 특혜활용을 위한 HS 품목분류 자가결정 방법에 대한 연구   \n",
       "...                                                ...   \n",
       "10302   가공된 순환자원을 시멘트 혼화재로 활용한 흙 시멘트 공시체의 강도 특성에 관한 연구   \n",
       "10303              E-Shape 강재이력댐퍼의 수치모델과 기초격리구조물의 지진응답   \n",
       "10304                  초등학교 5학년 영어 교과서 분석: 어휘학습전략 중심으로   \n",
       "10305                     도계 후 원료육의 저장기간 동안 가슴육의 품질 특성   \n",
       "10306  JMP+RAND: 바이너리 난수 삽입을 통한 메모리 공유 기반 부채널 공격 방어 기법   \n",
       "\n",
       "                                                      초록  \\\n",
       "0      본 시험은 충북지역 포도원 잡초방제별 생육 및 수량에 미치는 영향을 구명하기 위해 ...   \n",
       "1      컴프턴 산란 현상을 이용하여 전자적 집속 방법으로 영상화하는 컴프턴카메라는 고민감도...   \n",
       "2      선박의 항해사가 안전 항해를 위해 GPS, ARPA, AIS, NAVTEX, VHF...   \n",
       "3      홍천에는 카보내타이트-포스코라이트 복합체로 구성된 철-희토류 광상이 분포한다. 이 ...   \n",
       "4      FTA가 확대됨에 따라 FTA별로 상이한 원산지결정기준을 활용한 특혜 수혜가 점차 ...   \n",
       "...                                                  ...   \n",
       "10302  본 연구에서는 소성 굴패각, 비소성 굴패각, 자력선별된 전로 제강슬래그와 Fly a...   \n",
       "10303  최근 대규모의 지진피해로 인해 내진설계에 대한 관심이 높아지면서, LRB(Lead ...   \n",
       "10304  최근 외국어 학습에 있어 어휘 학습의 중요성이 부각되며 어휘학습전략 교육에 대한 관...   \n",
       "10305  본 연구는 도계 후 원료육의 저장기간에 따른 품질 특성을 조사하여 가공업소에서 반입...   \n",
       "10306  컴퓨터가 보급된 이래로 정보보안을 달성하기 위해 많은 노력이 이루어졌다. 그중 메모...   \n",
       "\n",
       "                           저널                      R1                  R2  \\\n",
       "0                      농약과학회지               시설원예ㆍ식물공장             원예과학기술지   \n",
       "1              한국의학물리학회지:의학물리          한국의학물리학회지:의학물리          한국방사선학회논문지   \n",
       "2                한국지능시스템학회논문지               한국항해항만학회지        디지털콘텐츠학회 논문지   \n",
       "3                       암석학회지                   암석학회지              자원환경지질   \n",
       "4                      통상정보연구                  통상정보연구           한국항만경제학회지   \n",
       "...                       ...                     ...                 ...   \n",
       "10302                 터널과지하공간           한국건설순환자원학회논문집  한국구조물진단유지관리공학회 논문집   \n",
       "10303               대한토목학회논문집            한국전산구조공학회논문집           대한토목학회논문집   \n",
       "10304              한국콘텐츠학회논문지             한국초등수학교육학회지   대한수학교육학회지:수학교육학연구   \n",
       "10305                 한국가금학회지                 원예과학기술지             한국가금학회지   \n",
       "10306  정보처리학회논문지:컴퓨터 및 통신 시스템  정보처리학회논문지:컴퓨터 및 통신 시스템        한국컴퓨터정보학회논문지   \n",
       "\n",
       "                       R3            R4                    R5  \n",
       "0                 한국가금학회지     한국응용곤충학회지                농업과학연구  \n",
       "1             한국정보통신학회논문지       한국음향학회지            대한방사선치료학회지  \n",
       "2             한국정보통신학회논문지  한국지능시스템학회논문지             해양환경안전학회지  \n",
       "3                 한국광물학회지      한국제4기학회지              한국지구과학회지  \n",
       "4                  유통과학연구  한국유통학회지:유통연구               경영과정보연구  \n",
       "...                   ...           ...                   ...  \n",
       "10302         한국콘크리트학회논문집     대한토목학회논문집             한국건축시공학회지  \n",
       "10303  한국구조물진단유지관리공학회 논문집   한국콘크리트학회논문집            대한기계학회논문집A  \n",
       "10304          한국학교수학회논문집    한국콘텐츠학회논문지  한국수학교육학회지시리즈C:초등수학교육  \n",
       "10305           시설원예ㆍ식물공장      대한환경공학회지                농업과학연구  \n",
       "10306          정보처리학회논문지C   한국정보통신학회논문지            인터넷정보학회논문지  \n",
       "\n",
       "[10307 rows x 8 columns]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 Dataframe 정리\n",
    "test_data_info = test[['title', 'abstract', 'journal']]\n",
    "rec_top_5 = pd.DataFrame(top_k_r, columns=['R1','R2','R3','R4','R5'])\n",
    "\n",
    "rec_result = pd.concat([test_data_info.reset_index(drop=True), rec_top_5], axis=1)#.rename(columns=)\n",
    "rec_result = rec_result.rename(columns={'title':'제목','abstract':'초록','journal':'저널'})\n",
    "rec_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81917f6b-f3df-4d57-a979-951d3e0ea008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 저장\n",
    "rec_result.to_csv('top5_result.csv', encoding='utf-8-sig')\n",
    "\n",
    "# rec_result = pd.read_csv('top5_result.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e84e2-2b16-4d7f-b7bb-c6933f4f6927",
   "metadata": {},
   "source": [
    "# 끝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
